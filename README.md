# 7B-DPO_MODEL_API
This is a repo created to test functionalities of ui-tars 7b dpo model.
